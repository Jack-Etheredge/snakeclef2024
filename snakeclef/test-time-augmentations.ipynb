{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377c7edd-c84e-4092-ab87-2a1188447f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/snakeclef-jsOUoRFY-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import ImageFile\n",
    "\n",
    "from closedset_model import build_model\n",
    "from competition_metrics import evaluate\n",
    "from datasets import get_valid_transform\n",
    "from paths import METADATA_DIR, VAL_DATA_DIR\n",
    "from utils import copy_config, get_device\n",
    "\n",
    "np.set_printoptions(precision=5)\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class PytorchWorker:\n",
    "    \"\"\"Run inference using PyTorch.\"\"\"\n",
    "\n",
    "    def __init__(self, model_path: str, number_of_categories: int = 1784, model_id=\"efficientnet_b0\", device=\"cpu\", transforms=None):\n",
    "\n",
    "        ########################################\n",
    "        # must be set before calling _load_model\n",
    "        self.number_of_categories = number_of_categories\n",
    "        self.model_id = model_id\n",
    "        self.device = device\n",
    "        ########################################\n",
    "\n",
    "        self.transforms = transforms\n",
    "        # most other attributes must be set before calling _load_model, so call last\n",
    "        self.model = self._load_model(model_path)\n",
    "\n",
    "    def _load_model(self, model_path):\n",
    "        print(\"Setting up Pytorch Model\")\n",
    "        # model = models.efficientnet_b0()\n",
    "        # model.classifier[1] = nn.Linear(in_features=1280, out_features=self.number_of_categories)\n",
    "        model = build_model(\n",
    "            model_id=self.model_id,\n",
    "            pretrained=False,\n",
    "            fine_tune=False,\n",
    "            num_classes=self.number_of_categories,\n",
    "            # this is all that matters. everything else will be overwritten by checkpoint state\n",
    "            dropout_rate=0.5,\n",
    "        ).to(self.device)\n",
    "        model_ckpt = torch.load(model_path, map_location=self.device)\n",
    "        model.load_state_dict(model_ckpt['model_state_dict'])\n",
    "\n",
    "        return model.to(self.device).eval()\n",
    "\n",
    "    def predict_image(self, image: np.ndarray) -> list():\n",
    "        \"\"\"Run inference using ONNX runtime.\n",
    "\n",
    "        :param image: Input image as numpy array.\n",
    "        :return: A list with logits and confidences.\n",
    "        \"\"\"\n",
    "\n",
    "        img = self.transforms(image)\n",
    "        \n",
    "        if isinstance(img, tuple):\n",
    "            img = torch.cat([instance.unsqueeze(0) for instance in img])\n",
    "            img = torch.unique(img, dim=0)\n",
    "\n",
    "        if img.dim() < 4:\n",
    "            img = img.unsqueeze(0)\n",
    "        \n",
    "        img = img.to(self.device)\n",
    "        \n",
    "        logits = self.model(img)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "def get_probas(test_metadata, model_id, model_path, images_root_path, device, transforms):\n",
    "    \"\"\"Make submission file\"\"\"\n",
    "\n",
    "    model = PytorchWorker(model_path, model_id=model_id, device=device, transforms=transforms)\n",
    "\n",
    "    probas_total = []\n",
    "    image_paths = test_metadata[\"image_path\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image_path in tqdm(image_paths):\n",
    "            image_path = os.path.join(images_root_path, image_path)\n",
    "            test_image = Image.open(image_path).convert(\"RGB\")\n",
    "            logits = model.predict_image(test_image)\n",
    "            probas = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()\n",
    "            if probas.shape[0] > 1:\n",
    "                probas = np.mean(probas, axis=0)\n",
    "            probas = probas.squeeze()\n",
    "            probas_total.append(probas)\n",
    "    \n",
    "    return probas_total\n",
    "\n",
    "\n",
    "def evaluate_experiment(cfgs, trial_name=None, multi_instance=False, device=\"cpu\", multicrop=False, debug=False):\n",
    "\n",
    "    submission_file_path = \"test-time-augmengations-submission.csv\"\n",
    "    if trial_name is not None:\n",
    "        submission_file_path = trial_name + submission_file_path\n",
    "\n",
    "    metadata_file_path = METADATA_DIR / \"SnakeCLEF2023-ValMetadata.csv\"\n",
    "    test_metadata = pd.read_csv(metadata_file_path)\n",
    "    if debug:\n",
    "        test_metadata = test_metadata.head(20)\n",
    "    if not multi_instance:\n",
    "        test_metadata.drop_duplicates(\"observation_id\", keep=\"first\", inplace=True)\n",
    "    \n",
    "    probas_per_model = []\n",
    "    for cfg in cfgs:\n",
    "        experiment_id = cfg[\"experiment_id\"]\n",
    "        if debug: print(f\"getting probas for experiment {experiment_id}\")\n",
    "        model_id = cfg[\"model_id\"]\n",
    "        image_size = cfg[\"image_size\"]\n",
    "        transforms = get_valid_transform(image_size=image_size, pretrained=True, fivecrop=multicrop)\n",
    "        experiment_dir = Path(\"model_checkpoints\") / experiment_id\n",
    "        predictions_output_csv_path = str(experiment_dir / \"submission.csv\")\n",
    "        model_file = \"model.pth\"\n",
    "        model_path = str(experiment_dir / model_file)\n",
    "        probas = get_probas(\n",
    "            model_id=model_id,\n",
    "            test_metadata=test_metadata,\n",
    "            model_path=model_path,\n",
    "            images_root_path=VAL_DATA_DIR,\n",
    "            device=device,\n",
    "            transforms=transforms,\n",
    "        )\n",
    "        probas_per_model.append(probas)\n",
    "    probas_per_model = np.array(probas_per_model)\n",
    "    if debug: print(\"probas_per_model.shape\", probas_per_model.shape)\n",
    "    if len(cfgs) > 1:\n",
    "        averaged_probas = np.mean(probas_per_model, axis=0)\n",
    "    else:\n",
    "        averaged_probas = probas_per_model.squeeze()\n",
    "    if debug: print(\"averaged_probas.shape\", averaged_probas.shape)\n",
    "    # if debug: print(\"np.argmax(averaged_probas)\", np.argmax(averaged_probas))\n",
    "\n",
    "    if multi_instance:\n",
    "        preds = []\n",
    "        # pandas unique preserves order\n",
    "        for obs_id in test_metadata[\"observation_id\"].unique():\n",
    "            indices = list(test_metadata[\"observation_id\"].loc[lambda x: x==obs_id].index)\n",
    "            if len(indices) > 1:\n",
    "                if debug: print(\"indices\", indices)\n",
    "                observation_probas = averaged_probas[indices, :]\n",
    "                observation_average = np.mean(averaged_probas[indices], axis=0)\n",
    "                if debug: print(\"observation_average.shape\", observation_average.shape)\n",
    "                preds.extend([np.argmax(observation_average)] * len(indices))\n",
    "            else:\n",
    "                preds.append(np.argmax(averaged_probas[indices], axis=1)[0])\n",
    "    else:\n",
    "        preds = np.argmax(averaged_probas, axis=1)\n",
    "\n",
    "    if debug:\n",
    "        print(\"preds\", preds)\n",
    "        if isinstance(preds, list):\n",
    "            preds = np.array(preds)\n",
    "        print(\"preds.shape\", preds.shape)\n",
    "    \n",
    "    submission_df = test_metadata.copy()\n",
    "    submission_df[\"class_id\"] = preds\n",
    "    submission_df = submission_df[[\"observation_id\", \"class_id\"]]\n",
    "    submission_df.drop_duplicates(\"observation_id\", keep=\"first\", inplace=True)\n",
    "    submission_df.to_csv(submission_file_path, index=False)\n",
    "\n",
    "    competition_metrics_scores = evaluate(\n",
    "        test_annotation_file=metadata_file_path,\n",
    "        user_submission_file=submission_file_path,\n",
    "        phase_codename=\"prediction-based\",\n",
    "    )[\"submission_result\"]\n",
    "\n",
    "    return competition_metrics_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c3c952-59ce-45e3-95e2-2920ec5b478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [08:45<00:00, 26.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [09:59<00:00, 23.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 57.67, 'Accuracy': 73.14, 'PSC': (25.07, 2.68, 6.2, 16.94), 'PSC_total': (1579, 169, 94, 257), 'Track1 Metric': 87.49, 'Track2 Metric': 2901}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_ensemble_multi = evaluate_experiment(cfgs=cfgs, trial_name=\"ensemble_multi-instance\",\n",
    "                                            multi_instance=True, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7188dbfd-4301-4449-bc0b-27e5d6acaa8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [04:11<00:00, 31.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [04:11<00:00, 31.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 55.53, 'Accuracy': 70.89, 'PSC': (27.19, 2.92, 6.86, 18.06), 'PSC_total': (1713, 184, 104, 274), 'Track1 Metric': 86.55, 'Track2 Metric': 3149}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_ensemble = evaluate_experiment(cfgs=cfgs, trial_name=\"ensemble\",\n",
    "                                      multi_instance=False, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a048c435-3782-4672-903a-bfbcecd4a53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [04:11<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 54.21, 'Accuracy': 70.48, 'PSC': (27.67, 2.86, 6.86, 18.46), 'PSC_total': (1743, 180, 104, 280), 'Track1 Metric': 86.33, 'Track2 Metric': 3183}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores = evaluate_experiment(cfgs=cfgs, trial_name=\"baseline\",\n",
    "                             multi_instance=False, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e76dffd-6c0a-4d51-9206-26e47a6277ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [07:34<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 56.0, 'Accuracy': 72.62, 'PSC': (25.67, 2.7, 6.06, 17.21), 'PSC_total': (1617, 170, 92, 261), 'Track1 Metric': 87.29, 'Track2 Metric': 2939}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "multi_scores = evaluate_experiment(cfgs=cfgs, trial_name=\"multi-instance\",\n",
    "                                   multi_instance=True, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be893672-f49c-44ed-a00f-17b52a03297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [27:26<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 55.5, 'Accuracy': 72.34, 'PSC': (26.13, 2.76, 5.87, 16.68), 'PSC_total': (1646, 174, 89, 253), 'Track1 Metric': 87.38, 'Track2 Metric': 2945}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "multicrop_scores = evaluate_experiment(cfgs=cfgs, trial_name=\"multi-instance_multicrop\",\n",
    "                                       multi_instance=True, device=device, multicrop=True, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b7d6b4b-2567-4b9f-bab6-bf77bffc0511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [15:19<00:00,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 54.2, 'Accuracy': 70.65, 'PSC': (27.5, 3.02, 6.86, 17.67), 'PSC_total': (1732, 190, 104, 268), 'Track1 Metric': 86.46, 'Track2 Metric': 3168}\n",
      "Completed evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "multicrop_single_scores = evaluate_experiment(cfgs=cfgs, trial_name=\"multicrop\",\n",
    "                                              multi_instance=False, multicrop=True, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d91800a-cd5f-46ca-ba27-c9cd6b841396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [35:31<00:00,  6.62it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [49:41<00:00,  4.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 58.04, 'Accuracy': 73.16, 'PSC': (25.19, 2.73, 5.74, 16.61), 'PSC_total': (1587, 172, 87, 252), 'Track1 Metric': 87.77, 'Track2 Metric': 2870}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_ensemble_multi_multicrop = evaluate_experiment(cfgs=cfgs, trial_name=\"ensemble_multi-instance_multicrop\",\n",
    "                                                      multi_instance=True, multicrop=True, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96386740-db72-4d27-9a80-b5c11a0afdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [07:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [07:02<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [06:55<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 56.4, 'Accuracy': 71.49, 'PSC': (26.43, 3.03, 6.53, 18.0), 'PSC_total': (1665, 191, 99, 273), 'Track1 Metric': 86.84, 'Track2 Metric': 3088}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 768,},\n",
    "\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-weighted_venom_loss\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_three_ensemble = evaluate_experiment(cfgs=cfgs, trial_name=\"three_ensemble\",\n",
    "                                            multi_instance=False, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d4d9368-338f-449e-8732-73f5b1c974c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [33:19<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [31:52<00:00,  7.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [24:55<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 58.68, 'Accuracy': 73.44, 'PSC': (24.72, 2.81, 5.74, 16.81), 'PSC_total': (1557, 177, 87, 255), 'Track1 Metric': 87.82, 'Track2 Metric': 2856}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 768,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 768,},\n",
    "\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-weighted_venom_loss\",\n",
    "    \"image_size\": 768,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_three_ensemble_multi_multicrop = evaluate_experiment(cfgs=cfgs, trial_name=\"three_ensemble_multi-instance_multicrop\",\n",
    "                                                            multi_instance=True, multicrop=True, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "067f7957-ac0c-4594-b1cd-985208d10169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [03:05<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [03:01<00:00, 43.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [03:02<00:00, 42.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 56.66, 'Accuracy': 71.48, 'PSC': (26.83, 2.94, 5.8, 17.53), 'PSC_total': (1690, 185, 88, 266), 'Track1 Metric': 87.26, 'Track2 Metric': 3032}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 576,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 576,},\n",
    "\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-weighted_venom_loss\",\n",
    "    \"image_size\": 576,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_three_ensemble_576 = evaluate_experiment(cfgs=cfgs, trial_name=\"three_ensemble_576\",\n",
    "                                                            multi_instance=False, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f7d315-0dd2-4137-9252-30b819621a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [05:39<00:00, 41.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 55.85, 'Accuracy': 72.52, 'PSC': (25.94, 2.94, 5.14, 16.55), 'PSC_total': (1634, 185, 78, 251), 'Track1 Metric': 87.75, 'Track2 Metric': 2896}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 576,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_multiinstance_576 = evaluate_experiment(cfgs=cfgs, trial_name=\"multi-instance_576\",\n",
    "                                                            multi_instance=True, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44d614ae-d5bb-4158-abf8-283ebceb9112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7816/7816 [03:01<00:00, 42.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 53.52, 'Accuracy': 70.51, 'PSC': (27.73, 3.18, 5.93, 17.67), 'PSC_total': (1747, 200, 90, 268), 'Track1 Metric': 86.77, 'Track2 Metric': 3133}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 576,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_576 = evaluate_experiment(cfgs=cfgs, trial_name=\"576\",\n",
    "                                                            multi_instance=False, multicrop=False, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53d256ed-16e0-4598-87bd-438395bba13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [11:40<00:00, 20.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 56.05, 'Accuracy': 72.76, 'PSC': (25.78, 2.95, 5.34, 15.69), 'PSC_total': (1624, 186, 81, 238), 'Track1 Metric': 87.84, 'Track2 Metric': 2877}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 576,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_multiinstance_multicrop_576 = evaluate_experiment(cfgs=cfgs, trial_name=\"multiinstance_multicrop_576\", multi_instance=True,\n",
    "                                                         multicrop=True, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc73856f-4700-492c-9ada-4c03d46f73c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [11:36<00:00, 20.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [11:22<00:00, 20.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Pytorch Model\n",
      "Not loading pre-trained weights\n",
      "Freezing hidden layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14117/14117 [12:47<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation.....\n",
      "Evaluating for Prediction-based Phase\n",
      "Evaluated scores: {'F1 Score': 59.1, 'Accuracy': 73.76, 'PSC': (24.8, 2.67, 5.08, 16.08), 'PSC_total': (1562, 168, 77, 244), 'Track1 Metric': 88.31, 'Track2 Metric': 2771}\n",
      "Completed evaluation\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-05 22:41:41.115323\",\n",
    "    \"image_size\": 576,},\n",
    "    \n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-focal-balanced-sampling-paused\",\n",
    "    \"image_size\": 576,},\n",
    "\n",
    "    {\"model_id\": \"caformer_s18.sail_in22k_ft_in1k_384\",\n",
    "     \"experiment_id\": \"2024-05-08-caformer_s18-weighted_venom_loss\",\n",
    "    \"image_size\": 576,},\n",
    "]\n",
    "device = get_device()\n",
    "scores_three_ensemble_multiinstance_multicrop_576 = evaluate_experiment(cfgs=cfgs, trial_name=\"three_ensemble_multiinstance_multicrop_576\",\n",
    "                                                            multi_instance=True, multicrop=True, device=device, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a95081-a9d5-4084-a378-2c17aae5dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_scores = {\n",
    "    \"ensemble_multi-instance\": scores_ensemble_multi,\n",
    "    \"ensemble\": scores_ensemble,\n",
    "    \"multi-instance\": multi_scores,\n",
    "    \"multi-instance_multicrop\": multicrop_scores,\n",
    "    \"multicrop\": multicrop_single_scores,\n",
    "    \"baseline\": scores,\n",
    "    \"ensemble_multi-instance_multicrop\": scores_ensemble_multi_multicrop,\n",
    "    \"three_ensemble\": scores_three_ensemble,\n",
    "    \"three_ensemble_multi-instance_multicrop\": scores_three_ensemble_multi_multicrop,\n",
    "    \"three_ensemble_576\": scores_three_ensemble_576,\n",
    "    \"multi-instance_576\": scores_multiinstance_576,\n",
    "    \"576\": scores_576,\n",
    "    \"multiinstance_multicrop_576\": scores_multiinstance_multicrop_576,\n",
    "    \"three_ensemble_multiinstance_multicrop_576\": scores_three_ensemble_multiinstance_multicrop_576,\n",
    "}\n",
    "# TODO: ability to load submission by trial_name\n",
    "\n",
    "dfs = []\n",
    "for name, score in named_scores.items():\n",
    "    keep_keys = {\"F1 Score\", \"Accuracy\", \"Track1 Metric\", \"Track2 Metric\"}\n",
    "    df = pd.DataFrame({k:v for k,v in score.items() if k in keep_keys}, index=[0])\n",
    "    df[\"experiment\"] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "score_comparison_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc21b759-638a-4a1c-afd2-79a196053f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Track1 Metric</th>\n",
       "      <th>Track2 Metric</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>56.05</td>\n",
       "      <td>72.76</td>\n",
       "      <td>87.84</td>\n",
       "      <td>2877</td>\n",
       "      <td>multiinstance_multicrop_576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58.68</td>\n",
       "      <td>73.44</td>\n",
       "      <td>87.82</td>\n",
       "      <td>2856</td>\n",
       "      <td>three_ensemble_multi-instance_multicrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58.04</td>\n",
       "      <td>73.16</td>\n",
       "      <td>87.77</td>\n",
       "      <td>2870</td>\n",
       "      <td>ensemble_multi-instance_multicrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55.85</td>\n",
       "      <td>72.52</td>\n",
       "      <td>87.75</td>\n",
       "      <td>2896</td>\n",
       "      <td>multi-instance_576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.67</td>\n",
       "      <td>73.14</td>\n",
       "      <td>87.49</td>\n",
       "      <td>2901</td>\n",
       "      <td>ensemble_multi-instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.50</td>\n",
       "      <td>72.34</td>\n",
       "      <td>87.38</td>\n",
       "      <td>2945</td>\n",
       "      <td>multi-instance_multicrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.00</td>\n",
       "      <td>72.62</td>\n",
       "      <td>87.29</td>\n",
       "      <td>2939</td>\n",
       "      <td>multi-instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.66</td>\n",
       "      <td>71.48</td>\n",
       "      <td>87.26</td>\n",
       "      <td>3032</td>\n",
       "      <td>three_ensemble_576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56.40</td>\n",
       "      <td>71.49</td>\n",
       "      <td>86.84</td>\n",
       "      <td>3088</td>\n",
       "      <td>three_ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.52</td>\n",
       "      <td>70.51</td>\n",
       "      <td>86.77</td>\n",
       "      <td>3133</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.53</td>\n",
       "      <td>70.89</td>\n",
       "      <td>86.55</td>\n",
       "      <td>3149</td>\n",
       "      <td>ensemble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.20</td>\n",
       "      <td>70.65</td>\n",
       "      <td>86.46</td>\n",
       "      <td>3168</td>\n",
       "      <td>multicrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54.21</td>\n",
       "      <td>70.48</td>\n",
       "      <td>86.33</td>\n",
       "      <td>3183</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1 Score  Accuracy  Track1 Metric  Track2 Metric  \\\n",
       "12     56.05     72.76          87.84           2877   \n",
       "8      58.68     73.44          87.82           2856   \n",
       "6      58.04     73.16          87.77           2870   \n",
       "10     55.85     72.52          87.75           2896   \n",
       "0      57.67     73.14          87.49           2901   \n",
       "3      55.50     72.34          87.38           2945   \n",
       "2      56.00     72.62          87.29           2939   \n",
       "9      56.66     71.48          87.26           3032   \n",
       "7      56.40     71.49          86.84           3088   \n",
       "11     53.52     70.51          86.77           3133   \n",
       "1      55.53     70.89          86.55           3149   \n",
       "4      54.20     70.65          86.46           3168   \n",
       "5      54.21     70.48          86.33           3183   \n",
       "\n",
       "                                 experiment  \n",
       "12              multiinstance_multicrop_576  \n",
       "8   three_ensemble_multi-instance_multicrop  \n",
       "6         ensemble_multi-instance_multicrop  \n",
       "10                       multi-instance_576  \n",
       "0                   ensemble_multi-instance  \n",
       "3                  multi-instance_multicrop  \n",
       "2                            multi-instance  \n",
       "9                        three_ensemble_576  \n",
       "7                            three_ensemble  \n",
       "11                                      576  \n",
       "1                                  ensemble  \n",
       "4                                 multicrop  \n",
       "5                                  baseline  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison_df.sort_values(\"Track1 Metric\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d530249-eb1a-4333-b299-f469d993a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(base_model, treatment):\n",
    "    for metric in ['Track1 Metric', 'Track2 Metric']:\n",
    "        print(metric, (score_comparison_df[score_comparison_df['experiment']==treatment][metric].values[0] - \n",
    "               score_comparison_df[score_comparison_df['experiment']==base_model][metric].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a6a04aa-7f43-45a5-9044-a2fb190ae46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.12999999999999545\n",
      "Track2 Metric -15\n"
     ]
    }
   ],
   "source": [
    "compare(\"single model\", \"multi-crop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9549c02-69e8-43b6-b81e-c9c77ffc31e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.9200000000000017\n",
      "Track2 Metric -223\n"
     ]
    }
   ],
   "source": [
    "compare(\"multi-crop\", \"multi-crop multi-instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ffa43f8-26cc-4ea3-aac1-3fc802f48eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.21999999999999886\n",
      "Track2 Metric -34\n"
     ]
    }
   ],
   "source": [
    "compare(\"single model\", \"ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e22236be-e0ff-4602-88e0-93064a3e0708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.29000000000000625\n",
      "Track2 Metric -61\n"
     ]
    }
   ],
   "source": [
    "compare(\"ensemble\", \"three ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af11246f-356a-42ef-bac6-c6fd33e958b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.960000000000008\n",
      "Track2 Metric -244\n"
     ]
    }
   ],
   "source": [
    "compare(\"single model\", \"multi-instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1ab8d74-8514-4dd6-89dc-501a5fddafdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.19999999999998863\n",
      "Track2 Metric -38\n"
     ]
    }
   ],
   "source": [
    "compare(\"multi-instance\", \"ensembled multi-instance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7728c36-c6ef-43fe-9ea1-ebe89c8fa63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track1 Metric 0.28000000000000114\n",
      "Track2 Metric -31\n"
     ]
    }
   ],
   "source": [
    "compare(\"ensembled multi-instance\", \"ensembled multi-crop multi-instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa899e5-a96d-447d-ac52-6d4b225dc9dc",
   "metadata": {},
   "source": [
    "## multi-instance > ensemble > multi-crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dbc1c-59f7-4da5-9956-3f6943671689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snakeclef",
   "language": "python",
   "name": "snakeclef"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
